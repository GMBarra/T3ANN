{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import utils as np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = 600\n",
    "x_train = np.load(\"./Dataset_parte_3/images_train.npy\")\n",
    "x_test = np.load(\"./Dataset_parte_3/images_test.npy\")\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "X_test = x_test.astype('float32') / 255.\n",
    "X_train = x_train[:-div]\n",
    "X_val = x_train[-div:]\n",
    "\n",
    "img_rows, img_cols,channel = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 480, 640, 3) (1000, 38) (600, 480, 640, 3) (600, 38)\n"
     ]
    }
   ],
   "source": [
    "y_training_set = pd.read_csv(\"./Dataset_parte_3/labels_train.csv\")\n",
    "one_hit = pd.get_dummies(y_training_set['count'])\n",
    "y_train = one_hit.values\n",
    "Y_train = y_train[:-div]\n",
    "Y_val = y_train[-div:]\n",
    "print(X_train.shape,Y_train.shape,X_val.shape,Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 240, 320, 480)     13440     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 80, 107, 480)      2074080   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 40, 53, 480)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 10, 14, 240)       1037040   \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 2, 3, 240)         518640    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 1, 1, 240)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              246784    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 38)                38950     \n",
      "=================================================================\n",
      "Total params: 3,928,934\n",
      "Trainable params: 3,928,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "from keras.optimizers import SGD\n",
    "import time\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(480, (3, 3), padding='same',input_shape=x_train.shape[1:],strides=2,activation='relu'))\n",
    "model.add(Conv2D(480, (3, 3),padding='same',activation='relu',strides=3))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(240, (3, 3),padding='same',activation='relu',strides=4))\n",
    "model.add(Conv2D(240, (3, 3),padding='same',activation='relu',strides=5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(38,activation = \"softmax\"))\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum = 0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_8 to have 2 dimensions, but got array with shape (1000, 480, 640, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-20326bbcb08d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_8 to have 2 dimensions, but got array with shape (1000, 480, 640, 3)"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,Y_train,epochs=15,batch_size=2,validation_data=(X_val,Y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 480, 640, 9)       252       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 480, 640, 3)       246       \n",
      "=================================================================\n",
      "Total params: 498\n",
      "Trainable params: 498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1000 samples, validate on 600 samples\n",
      "Epoch 1/15\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 1.5463 - acc: 0.8988 - val_loss: 1.5547 - val_acc: 0.9223\n",
      "Epoch 2/15\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 1.5440 - acc: 0.9406 - val_loss: 1.5544 - val_acc: 0.9365\n",
      "Epoch 3/15\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 1.5438 - acc: 0.9511 - val_loss: 1.5543 - val_acc: 0.9489\n",
      "Epoch 4/15\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 1.5438 - acc: 0.9591 - val_loss: 1.5543 - val_acc: 0.9545\n",
      "Epoch 5/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5437 - acc: 0.9639 - val_loss: 1.5542 - val_acc: 0.9605\n",
      "Epoch 6/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5437 - acc: 0.9670 - val_loss: 1.5542 - val_acc: 0.9614\n",
      "Epoch 7/15\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 1.5437 - acc: 0.9688 - val_loss: 1.5542 - val_acc: 0.9646\n",
      "Epoch 8/15\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 1.5436 - acc: 0.9721 - val_loss: 1.5541 - val_acc: 0.9746\n",
      "Epoch 9/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5436 - acc: 0.9778 - val_loss: 1.5541 - val_acc: 0.9788\n",
      "Epoch 10/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5436 - acc: 0.9797 - val_loss: 1.5541 - val_acc: 0.9788\n",
      "Epoch 11/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5436 - acc: 0.9802 - val_loss: 1.5541 - val_acc: 0.9785\n",
      "Epoch 12/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5436 - acc: 0.9807 - val_loss: 1.5541 - val_acc: 0.9771\n",
      "Epoch 13/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5436 - acc: 0.9813 - val_loss: 1.5541 - val_acc: 0.9759\n",
      "Epoch 14/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5436 - acc: 0.9817 - val_loss: 1.5541 - val_acc: 0.9789\n",
      "Epoch 15/15\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5436 - acc: 0.9821 - val_loss: 1.5541 - val_acc: 0.9751\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 480, 640, 9)       252       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 480, 640, 12)      984       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 480, 640, 9)       981       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 480, 640, 3)       246       \n",
      "=================================================================\n",
      "Total params: 2,463\n",
      "Trainable params: 1,965\n",
      "Non-trainable params: 498\n",
      "_________________________________________________________________\n",
      "Train on 1000 samples, validate on 600 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: loss_2/conv2d_4_loss/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_2/conv2d_4_loss/NotEqual)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape/_311 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_165_training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'loss_2/conv2d_4_loss/Cast', defined at:\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ef63a301cc5a>\", line 25, in <module>\n    autoencoder2.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\", line 830, in compile\n    sample_weight, mask)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\", line 446, in weighted\n    score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 947, in cast\n    return tf.cast(x, dtype)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 787, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1613, in cast\n    \"Cast\", x=x, DstT=DstT, name=name)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: loss_2/conv2d_4_loss/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_2/conv2d_4_loss/NotEqual)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape/_311 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_165_training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: loss_2/conv2d_4_loss/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_2/conv2d_4_loss/NotEqual)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape/_311 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_165_training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ef63a301cc5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mautoencoder2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mautoencoder2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mhist_autoencoder2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mautoencoder2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'autoencoder_layer2.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#FINE TUNNING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: loss_2/conv2d_4_loss/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_2/conv2d_4_loss/NotEqual)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape/_311 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_165_training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'loss_2/conv2d_4_loss/Cast', defined at:\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ef63a301cc5a>\", line 25, in <module>\n    autoencoder2.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\", line 830, in compile\n    sample_weight, mask)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py\", line 446, in weighted\n    score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 947, in cast\n    return tf.cast(x, dtype)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 787, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1613, in cast\n    \"Cast\", x=x, DstT=DstT, name=name)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: loss_2/conv2d_4_loss/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_2/conv2d_4_loss/NotEqual)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape/_311 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_165_training_2/Adam/gradients/loss_2/conv2d_4_loss/Sum_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "###BUILD AUTOENCODER1\n",
    "hidden_layer1 = 9\n",
    "hidden_layer2 = 12\n",
    "\n",
    "\n",
    "input_img = Input(shape=X_train.shape[1:])\n",
    "encoded1 = Conv2D(hidden_layer1, (3, 3),activation='relu',padding='same')(input_img)\n",
    "decoded1 = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(encoded1)\n",
    "autoencoder1 = Model(input_img, decoded1)\n",
    "autoencoder1.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "autoencoder1.summary()\n",
    "hist_autoencoder1 = autoencoder1.fit(X_train, X_train, epochs=15, batch_size=2,validation_data=(X_val, X_val))\n",
    "autoencoder1.save('autoencoder_layer1.h5')\n",
    "###BUILD AUTOENCODER2\n",
    "encoded1 = autoencoder1.layers[1](autoencoder1.input)\n",
    "#AUTOENCODER2\n",
    "encoded2 = Conv2D(hidden_layer2,(3, 3), activation='relu', padding='same')(encoded1) \n",
    "decoded2 = Conv2D(hidden_layer1,(3, 3), activation='sigmoid',padding='same')(encoded2) \n",
    "#finish AUTOENCODER2\n",
    "decoded1 = autoencoder1.layers[-1](decoded2)\n",
    "autoencoder2 = Model(autoencoder1.input, decoded1) #all model\n",
    "#autoencoder1 set fixed\n",
    "autoencoder2.layers[1].trainable=False\n",
    "autoencoder2.layers[-1].trainable=False\n",
    "autoencoder2.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "autoencoder2.summary()\n",
    "hist_autoencoder2 = autoencoder2.fit(X_train, X_train, epochs=15, batch_size=128,validation_data=(X_val, X_val))\n",
    "autoencoder2.save('autoencoder_layer2.h5')\n",
    "#FINE TUNNING\n",
    "model = Sequential()\n",
    "model.add(Conv2D(hidden_layer1,(3, 3),padding='same',activation='relu',input_shape=x_train.shape[1:]))\n",
    "model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
    "model.add(Conv2D(hidden_layer2, (3, 3),padding='same',activation='relu'))\n",
    "model.layers[-1].set_weights(autoencoder2.layers[2].get_weights())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='sigmoid'))\n",
    "model.add(Dense(100,activation = \"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01,momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_modelC = model.fit(x_train, y_train, batch_size=128,epochs=15,verbose=1, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
