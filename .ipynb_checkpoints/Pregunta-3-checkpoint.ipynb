{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teikkenn\\AppData\\Local\\conda\\conda\\envs\\ann\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.constraints import maxnorm\n",
    "from keras import utils as np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = 200\n",
    "x_train = np.load(\"./Dataset_parte_3/images_train.npy\")\n",
    "x_test = np.load(\"./Dataset_parte_3/images_test.npy\")\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "X_test = x_test.astype('float32') / 255.\n",
    "X_train = x_train[:-div]\n",
    "X_val = x_train[-div:]\n",
    "\n",
    "img_rows, img_cols,channel = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training_set = pd.read_csv(\"./Dataset_parte_3/labels_train.csv\")\n",
    "one_hit = y_training_set['count']\n",
    "#y_train = one_hit.values\n",
    "Y_train = one_hit[:-div]\n",
    "Y_val = one_hit[-div:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_312 (Conv2D)          (None, 480, 640, 8)       392       \n",
      "_________________________________________________________________\n",
      "conv2d_313 (Conv2D)          (None, 477, 637, 8)       1032      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_152 (MaxPoolin (None, 238, 318, 8)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 238, 318, 8)       32        \n",
      "_________________________________________________________________\n",
      "conv2d_314 (Conv2D)          (None, 238, 318, 16)      2064      \n",
      "_________________________________________________________________\n",
      "conv2d_315 (Conv2D)          (None, 235, 315, 16)      4112      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_153 (MaxPoolin (None, 117, 157, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 117, 157, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_316 (Conv2D)          (None, 117, 157, 32)      8224      \n",
      "_________________________________________________________________\n",
      "conv2d_317 (Conv2D)          (None, 114, 154, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_154 (MaxPoolin (None, 57, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 57, 77, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_318 (Conv2D)          (None, 57, 77, 64)        32832     \n",
      "_________________________________________________________________\n",
      "conv2d_319 (Conv2D)          (None, 54, 74, 64)        65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_155 (MaxPoolin (None, 27, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 27, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_320 (Conv2D)          (None, 27, 37, 128)       131200    \n",
      "_________________________________________________________________\n",
      "conv2d_321 (Conv2D)          (None, 24, 34, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_156 (MaxPoolin (None, 12, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 12, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_322 (Conv2D)          (None, 12, 17, 256)       524544    \n",
      "_________________________________________________________________\n",
      "conv2d_323 (Conv2D)          (None, 9, 14, 256)        1048832   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_157 (MaxPoolin (None, 4, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 4, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 7168)              28672     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1024)              7341056   \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 516)               528900    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 256)               132352    \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 10,172,757\n",
      "Trainable params: 10,157,925\n",
      "Non-trainable params: 14,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def createModel(dimensiones):\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(8, (4, 4), padding='same', activation='sigmoid', input_shape=dimensiones))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16, (4, 4), padding='same', activation='sigmoid'))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (4, 4), padding='same', activation='sigmoid'))\n",
    "    model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (4, 4), padding='same', activation='sigmoid'))\n",
    "    model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (4, 4), padding='same', activation='sigmoid'))\n",
    "    model.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (4, 4), padding='same', activation='sigmoid'))\n",
    "    model.add(Conv2D(256, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(516, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "   \n",
    "    return model\n",
    "\n",
    "model1 = createModel(X_train.shape[1:])\n",
    "model1.compile(loss=root_mean_squared_error, optimizer='rmsprop', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 200 samples\n",
      "Epoch 1/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 10.4531 - acc: 0.0314 - val_loss: 7.3004 - val_acc: 0.0450\n",
      "Epoch 2/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 9.2407 - acc: 0.0364 - val_loss: 9.4422 - val_acc: 0.0100\n",
      "Epoch 3/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 7.3067 - acc: 0.0379 - val_loss: 19.6921 - val_acc: 0.0000e+00\n",
      "Epoch 4/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 6.4677 - acc: 0.0521 - val_loss: 21.4441 - val_acc: 0.0000e+00\n",
      "Epoch 5/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 5.6964 - acc: 0.0564 - val_loss: 6.9111 - val_acc: 0.0300\n",
      "Epoch 6/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 5.3023 - acc: 0.0500 - val_loss: 19.1308 - val_acc: 0.0000e+00\n",
      "Epoch 7/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 4.7829 - acc: 0.0686 - val_loss: 25.6586 - val_acc: 0.0000e+00\n",
      "Epoch 8/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 4.4622 - acc: 0.0771 - val_loss: 19.8563 - val_acc: 0.0000e+00\n",
      "Epoch 9/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 4.5368 - acc: 0.0700 - val_loss: 22.0333 - val_acc: 0.0000e+00\n",
      "Epoch 10/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 4.3913 - acc: 0.0629 - val_loss: 20.0835 - val_acc: 0.0000e+00\n",
      "Epoch 11/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 4.0497 - acc: 0.0700 - val_loss: 24.3776 - val_acc: 0.0000e+00\n",
      "Epoch 12/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.9971 - acc: 0.0800 - val_loss: 7.3199 - val_acc: 0.0100\n",
      "Epoch 13/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.7458 - acc: 0.1057 - val_loss: 51.8939 - val_acc: 0.0000e+00\n",
      "Epoch 14/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.8140 - acc: 0.0914 - val_loss: 18.2793 - val_acc: 0.0000e+00\n",
      "Epoch 15/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.8654 - acc: 0.0800 - val_loss: 14.6420 - val_acc: 0.0000e+00\n",
      "Epoch 16/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.7937 - acc: 0.0964 - val_loss: 54.9084 - val_acc: 0.0000e+00\n",
      "Epoch 17/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.5813 - acc: 0.0971 - val_loss: 53.8748 - val_acc: 0.0000e+00\n",
      "Epoch 18/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.5555 - acc: 0.0786 - val_loss: 19.4226 - val_acc: 0.0000e+00\n",
      "Epoch 19/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.4263 - acc: 0.0914 - val_loss: 52.0246 - val_acc: 0.0000e+00\n",
      "Epoch 20/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.4696 - acc: 0.0800 - val_loss: 13.3194 - val_acc: 0.0150\n",
      "Epoch 21/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.5885 - acc: 0.1029 - val_loss: 12.0307 - val_acc: 0.0000e+00\n",
      "Epoch 22/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.4869 - acc: 0.0857 - val_loss: 25.5431 - val_acc: 0.0000e+00\n",
      "Epoch 23/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.4761 - acc: 0.0957 - val_loss: 4.7185 - val_acc: 0.0500\n",
      "Epoch 24/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.2399 - acc: 0.1071 - val_loss: 19.9603 - val_acc: 0.0000e+00\n",
      "Epoch 25/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.3295 - acc: 0.0929 - val_loss: 16.5505 - val_acc: 0.0000e+00\n",
      "Epoch 26/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.2922 - acc: 0.0957 - val_loss: 18.8661 - val_acc: 0.0000e+00\n",
      "Epoch 27/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.4691 - acc: 0.0957 - val_loss: 25.8861 - val_acc: 0.0000e+00\n",
      "Epoch 28/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.3678 - acc: 0.0936 - val_loss: 21.7325 - val_acc: 0.0000e+00\n",
      "Epoch 29/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.1002 - acc: 0.1079 - val_loss: 18.8798 - val_acc: 0.0000e+00\n",
      "Epoch 30/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.2836 - acc: 0.0979 - val_loss: 28.6621 - val_acc: 0.0000e+00\n",
      "Epoch 31/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.1923 - acc: 0.0943 - val_loss: 16.2775 - val_acc: 0.0000e+00\n",
      "Epoch 32/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.3679 - acc: 0.1064 - val_loss: 7.0973 - val_acc: 0.0000e+00\n",
      "Epoch 33/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.0661 - acc: 0.1136 - val_loss: 25.8650 - val_acc: 0.0000e+00\n",
      "Epoch 34/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.2347 - acc: 0.1143 - val_loss: 20.1119 - val_acc: 0.0000e+00\n",
      "Epoch 35/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.1010 - acc: 0.0950 - val_loss: 23.9446 - val_acc: 0.0000e+00\n",
      "Epoch 36/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 3.1987 - acc: 0.0964 - val_loss: 34.8530 - val_acc: 0.0000e+00\n",
      "Epoch 37/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 3.0681 - acc: 0.1029 - val_loss: 22.1790 - val_acc: 0.0000e+00\n",
      "Epoch 38/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 3.2385 - acc: 0.0829 - val_loss: 15.2898 - val_acc: 0.0000e+00\n",
      "Epoch 39/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.3476 - acc: 0.0950 - val_loss: 20.7570 - val_acc: 0.0000e+00\n",
      "Epoch 40/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.1007 - acc: 0.0986 - val_loss: 20.8811 - val_acc: 0.0000e+00\n",
      "Epoch 41/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.1312 - acc: 0.1007 - val_loss: 18.9286 - val_acc: 0.0000e+00\n",
      "Epoch 42/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 3.0735 - acc: 0.1043 - val_loss: 34.4847 - val_acc: 0.0000e+00\n",
      "Epoch 43/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 3.1064 - acc: 0.1086 - val_loss: 29.4608 - val_acc: 0.0000e+00\n",
      "Epoch 44/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 3.2052 - acc: 0.1071 - val_loss: 22.6737 - val_acc: 0.0000e+00\n",
      "Epoch 45/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.8594 - acc: 0.1221 - val_loss: 78.4255 - val_acc: 0.0000e+00\n",
      "Epoch 46/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 3.1409 - acc: 0.1036 - val_loss: 20.4864 - val_acc: 0.0000e+00\n",
      "Epoch 47/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.9093 - acc: 0.1043 - val_loss: 17.2612 - val_acc: 0.0000e+00\n",
      "Epoch 48/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.8688 - acc: 0.1114 - val_loss: 63.1971 - val_acc: 0.0000e+00\n",
      "Epoch 49/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.6467 - acc: 0.1336 - val_loss: 29.6403 - val_acc: 0.0000e+00\n",
      "Epoch 50/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.9367 - acc: 0.1121 - val_loss: 13.0116 - val_acc: 0.0000e+00\n",
      "Epoch 51/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.8920 - acc: 0.1086 - val_loss: 14.1057 - val_acc: 0.0000e+00\n",
      "Epoch 52/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.6812 - acc: 0.1193 - val_loss: 23.8532 - val_acc: 0.0000e+00\n",
      "Epoch 53/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 3.0352 - acc: 0.0936 - val_loss: 14.0890 - val_acc: 0.0000e+00\n",
      "Epoch 54/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.5702 - acc: 0.1293 - val_loss: 54.5156 - val_acc: 0.0000e+00\n",
      "Epoch 55/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.7999 - acc: 0.1186 - val_loss: 96.4001 - val_acc: 0.0000e+00\n",
      "Epoch 56/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.9741 - acc: 0.1129 - val_loss: 40.3484 - val_acc: 0.0000e+00\n",
      "Epoch 57/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.8249 - acc: 0.1200 - val_loss: 87.2616 - val_acc: 0.0000e+00\n",
      "Epoch 58/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.8830 - acc: 0.1064 - val_loss: 9.9857 - val_acc: 0.0000e+00\n",
      "Epoch 59/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.8070 - acc: 0.1164 - val_loss: 10.0078 - val_acc: 0.0000e+00\n",
      "Epoch 60/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.9280 - acc: 0.1150 - val_loss: 13.4950 - val_acc: 0.0000e+00\n",
      "Epoch 61/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.8867 - acc: 0.1050 - val_loss: 83.7314 - val_acc: 0.0000e+00\n",
      "Epoch 62/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.7986 - acc: 0.1243 - val_loss: 75.9693 - val_acc: 0.0000e+00\n",
      "Epoch 63/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.8349 - acc: 0.1193 - val_loss: 13.8007 - val_acc: 0.0000e+00\n",
      "Epoch 64/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.7033 - acc: 0.1179 - val_loss: 9.1711 - val_acc: 0.0000e+00\n",
      "Epoch 65/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 3.1120 - acc: 0.1029 - val_loss: 11.9763 - val_acc: 0.0000e+00\n",
      "Epoch 66/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.8025 - acc: 0.1186 - val_loss: 17.6610 - val_acc: 0.0000e+00\n",
      "Epoch 67/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.6035 - acc: 0.1386 - val_loss: 24.8347 - val_acc: 0.0000e+00\n",
      "Epoch 68/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.8705 - acc: 0.1157 - val_loss: 79.3134 - val_acc: 0.0000e+00\n",
      "Epoch 69/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.7952 - acc: 0.1143 - val_loss: 8.0762 - val_acc: 0.0000e+00\n",
      "Epoch 70/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.7539 - acc: 0.1164 - val_loss: 32.4206 - val_acc: 0.0000e+00\n",
      "Epoch 71/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.7425 - acc: 0.1350 - val_loss: 6.4861 - val_acc: 0.0100\n",
      "Epoch 72/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.9525 - acc: 0.1043 - val_loss: 11.0514 - val_acc: 0.0000e+00\n",
      "Epoch 73/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.5828 - acc: 0.1286 - val_loss: 4.2650 - val_acc: 0.0650\n",
      "Epoch 74/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.7236 - acc: 0.1214 - val_loss: 13.2443 - val_acc: 0.0000e+00\n",
      "Epoch 75/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.5876 - acc: 0.1286 - val_loss: 3.6744 - val_acc: 0.0550\n",
      "Epoch 76/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.8360 - acc: 0.1307 - val_loss: 7.1754 - val_acc: 0.0050\n",
      "Epoch 77/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.6429 - acc: 0.1236 - val_loss: 13.7861 - val_acc: 0.0000e+00\n",
      "Epoch 78/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.4789 - acc: 0.1386 - val_loss: 20.1891 - val_acc: 0.0000e+00\n",
      "Epoch 79/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.5388 - acc: 0.1471 - val_loss: 4.5632 - val_acc: 0.0450\n",
      "Epoch 80/250\n",
      "1400/1400 [==============================] - 50s 35ms/step - loss: 2.6342 - acc: 0.1214 - val_loss: 35.5422 - val_acc: 0.0000e+00\n",
      "Epoch 81/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.6231 - acc: 0.1186 - val_loss: 7.1068 - val_acc: 0.0050\n",
      "Epoch 82/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.6380 - acc: 0.1186 - val_loss: 21.4006 - val_acc: 0.0000e+00\n",
      "Epoch 83/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.7060 - acc: 0.1129 - val_loss: 8.3738 - val_acc: 0.0000e+00\n",
      "Epoch 84/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.6461 - acc: 0.1250 - val_loss: 10.4683 - val_acc: 0.0000e+00\n",
      "Epoch 85/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.5055 - acc: 0.1307 - val_loss: 2.2637 - val_acc: 0.1150\n",
      "Epoch 86/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.4971 - acc: 0.1436 - val_loss: 11.4678 - val_acc: 0.0000e+00\n",
      "Epoch 87/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.7656 - acc: 0.1207 - val_loss: 3.1388 - val_acc: 0.0600\n",
      "Epoch 88/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5664 - acc: 0.1300 - val_loss: 15.6550 - val_acc: 0.0000e+00\n",
      "Epoch 89/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.4500 - acc: 0.1457 - val_loss: 6.2315 - val_acc: 0.0250\n",
      "Epoch 90/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.6706 - acc: 0.1193 - val_loss: 12.5425 - val_acc: 0.0000e+00\n",
      "Epoch 91/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5007 - acc: 0.1179 - val_loss: 2.3302 - val_acc: 0.1300\n",
      "Epoch 92/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.4230 - acc: 0.1186 - val_loss: 5.0142 - val_acc: 0.0250\n",
      "Epoch 93/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5895 - acc: 0.1214 - val_loss: 7.2091 - val_acc: 0.0000e+00\n",
      "Epoch 94/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.2709 - acc: 0.1421 - val_loss: 36.2772 - val_acc: 0.0000e+00\n",
      "Epoch 95/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.5578 - acc: 0.1143 - val_loss: 7.5069 - val_acc: 0.0000e+00\n",
      "Epoch 96/250\n",
      "1400/1400 [==============================] - 50s 35ms/step - loss: 2.5639 - acc: 0.1100 - val_loss: 17.5145 - val_acc: 0.0000e+00\n",
      "Epoch 97/250\n",
      "1400/1400 [==============================] - 50s 35ms/step - loss: 2.5961 - acc: 0.1271 - val_loss: 18.2586 - val_acc: 0.0000e+00\n",
      "Epoch 98/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.5522 - acc: 0.1157 - val_loss: 2.9861 - val_acc: 0.0500\n",
      "Epoch 99/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5665 - acc: 0.1271 - val_loss: 18.1975 - val_acc: 0.0000e+00\n",
      "Epoch 100/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.6859 - acc: 0.1179 - val_loss: 91.6658 - val_acc: 0.0000e+00\n",
      "Epoch 101/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.3889 - acc: 0.1300 - val_loss: 2.6398 - val_acc: 0.0900\n",
      "Epoch 102/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.7009 - acc: 0.1186 - val_loss: 24.7605 - val_acc: 0.0000e+00\n",
      "Epoch 103/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.4771 - acc: 0.1186 - val_loss: 6.7019 - val_acc: 0.0200\n",
      "Epoch 104/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.4402 - acc: 0.1343 - val_loss: 8.5495 - val_acc: 0.0100\n",
      "Epoch 105/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.4552 - acc: 0.1293 - val_loss: 8.5162 - val_acc: 0.0000e+00\n",
      "Epoch 106/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5757 - acc: 0.1171 - val_loss: 4.8002 - val_acc: 0.0300\n",
      "Epoch 107/250\n",
      "1400/1400 [==============================] - 50s 35ms/step - loss: 2.2980 - acc: 0.1371 - val_loss: 9.0790 - val_acc: 0.0000e+00\n",
      "Epoch 108/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.4292 - acc: 0.1393 - val_loss: 6.8676 - val_acc: 0.0100\n",
      "Epoch 109/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.3695 - acc: 0.1286 - val_loss: 9.8163 - val_acc: 0.0000e+00\n",
      "Epoch 110/250\n",
      "1400/1400 [==============================] - 50s 35ms/step - loss: 2.4052 - acc: 0.1407 - val_loss: 13.5260 - val_acc: 0.0000e+00\n",
      "Epoch 111/250\n",
      "1400/1400 [==============================] - 50s 35ms/step - loss: 2.5211 - acc: 0.1157 - val_loss: 5.1450 - val_acc: 0.0350\n",
      "Epoch 112/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5572 - acc: 0.1064 - val_loss: 5.1554 - val_acc: 0.0150\n",
      "Epoch 113/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5609 - acc: 0.1407 - val_loss: 12.3474 - val_acc: 0.0000e+00\n",
      "Epoch 114/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.3100 - acc: 0.1229 - val_loss: 21.6313 - val_acc: 0.0000e+00\n",
      "Epoch 115/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.5336 - acc: 0.1186 - val_loss: 9.1318 - val_acc: 0.0000e+00\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.4553 - acc: 0.1250 - val_loss: 4.0159 - val_acc: 0.0700\n",
      "Epoch 117/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.4396 - acc: 0.1471 - val_loss: 28.9132 - val_acc: 0.0000e+00\n",
      "Epoch 118/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.3212 - acc: 0.1336 - val_loss: 5.3137 - val_acc: 0.0350\n",
      "Epoch 119/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.3698 - acc: 0.1457 - val_loss: 7.3080 - val_acc: 0.0100\n",
      "Epoch 120/250\n",
      "1400/1400 [==============================] - 50s 36ms/step - loss: 2.3215 - acc: 0.1421 - val_loss: 9.4934 - val_acc: 0.0000e+00\n",
      "Epoch 121/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.3512 - acc: 0.1407 - val_loss: 5.7057 - val_acc: 0.0250\n",
      "Epoch 122/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.4537 - acc: 0.1321 - val_loss: 5.3377 - val_acc: 0.0450\n",
      "Epoch 123/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.3802 - acc: 0.1336 - val_loss: 3.6636 - val_acc: 0.0700\n",
      "Epoch 124/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.4658 - acc: 0.1436 - val_loss: 12.4139 - val_acc: 0.0000e+00\n",
      "Epoch 125/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.3774 - acc: 0.1336 - val_loss: 2.0664 - val_acc: 0.1500\n",
      "Epoch 126/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.4572 - acc: 0.1221 - val_loss: 2.5110 - val_acc: 0.1500\n",
      "Epoch 127/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.3286 - acc: 0.1414 - val_loss: 13.6730 - val_acc: 0.0000e+00\n",
      "Epoch 128/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.2788 - acc: 0.1464 - val_loss: 16.6881 - val_acc: 0.0000e+00\n",
      "Epoch 129/250\n",
      "1400/1400 [==============================] - 45s 32ms/step - loss: 2.2169 - acc: 0.1493 - val_loss: 28.7496 - val_acc: 0.0000e+00\n",
      "Epoch 130/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.2919 - acc: 0.1350 - val_loss: 11.0695 - val_acc: 0.0000e+00\n",
      "Epoch 131/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.3341 - acc: 0.1321 - val_loss: 12.2942 - val_acc: 0.0000e+00\n",
      "Epoch 132/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.5087 - acc: 0.1379 - val_loss: 6.8894 - val_acc: 0.0150\n",
      "Epoch 133/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.2749 - acc: 0.1507 - val_loss: 7.1738 - val_acc: 0.0100\n",
      "Epoch 134/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 2.2909 - acc: 0.1421 - val_loss: 16.9755 - val_acc: 0.0000e+00\n",
      "Epoch 135/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.3706 - acc: 0.1464 - val_loss: 5.9697 - val_acc: 0.0250\n",
      "Epoch 136/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2768 - acc: 0.1400 - val_loss: 9.9940 - val_acc: 0.0000e+00\n",
      "Epoch 137/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2831 - acc: 0.1429 - val_loss: 12.2860 - val_acc: 0.0000e+00\n",
      "Epoch 138/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.3474 - acc: 0.1343 - val_loss: 7.5729 - val_acc: 0.0050\n",
      "Epoch 139/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2202 - acc: 0.1643 - val_loss: 2.4264 - val_acc: 0.0950\n",
      "Epoch 140/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.3463 - acc: 0.1486 - val_loss: 6.8116 - val_acc: 0.0050\n",
      "Epoch 141/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2925 - acc: 0.1336 - val_loss: 6.4956 - val_acc: 0.0000e+00\n",
      "Epoch 142/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1961 - acc: 0.1529 - val_loss: 14.3715 - val_acc: 0.0000e+00\n",
      "Epoch 143/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1951 - acc: 0.1600 - val_loss: 14.3984 - val_acc: 0.0000e+00\n",
      "Epoch 144/250\n",
      "1400/1400 [==============================] - 45s 32ms/step - loss: 2.1421 - acc: 0.1529 - val_loss: 14.5650 - val_acc: 0.0000e+00\n",
      "Epoch 145/250\n",
      "1400/1400 [==============================] - 45s 32ms/step - loss: 2.3581 - acc: 0.1350 - val_loss: 7.6925 - val_acc: 0.0000e+00\n",
      "Epoch 146/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.2732 - acc: 0.1336 - val_loss: 9.3385 - val_acc: 0.0000e+00\n",
      "Epoch 147/250\n",
      "1400/1400 [==============================] - 45s 32ms/step - loss: 2.3066 - acc: 0.1243 - val_loss: 2.6053 - val_acc: 0.1400\n",
      "Epoch 148/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.1903 - acc: 0.1593 - val_loss: 21.4248 - val_acc: 0.0000e+00\n",
      "Epoch 149/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.2281 - acc: 0.1450 - val_loss: 21.1952 - val_acc: 0.0000e+00\n",
      "Epoch 150/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.3091 - acc: 0.1386 - val_loss: 4.4991 - val_acc: 0.0300\n",
      "Epoch 151/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.1130 - acc: 0.1629 - val_loss: 8.9008 - val_acc: 0.0000e+00\n",
      "Epoch 152/250\n",
      "1400/1400 [==============================] - 45s 32ms/step - loss: 2.3655 - acc: 0.1400 - val_loss: 13.4342 - val_acc: 0.0000e+00\n",
      "Epoch 153/250\n",
      "1400/1400 [==============================] - 45s 32ms/step - loss: 2.2467 - acc: 0.1500 - val_loss: 30.1069 - val_acc: 0.0000e+00\n",
      "Epoch 154/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.4493 - acc: 0.1279 - val_loss: 21.8758 - val_acc: 0.0000e+00\n",
      "Epoch 155/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0805 - acc: 0.1464 - val_loss: 11.5383 - val_acc: 0.0000e+00\n",
      "Epoch 156/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.3866 - acc: 0.1364 - val_loss: 10.6095 - val_acc: 0.0000e+00\n",
      "Epoch 157/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2447 - acc: 0.1493 - val_loss: 5.2413 - val_acc: 0.0300\n",
      "Epoch 158/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.3855 - acc: 0.1193 - val_loss: 6.9711 - val_acc: 0.0050\n",
      "Epoch 159/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1559 - acc: 0.1650 - val_loss: 7.7476 - val_acc: 0.0050\n",
      "Epoch 160/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.2220 - acc: 0.1693 - val_loss: 9.8442 - val_acc: 0.0000e+00\n",
      "Epoch 161/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1602 - acc: 0.1543 - val_loss: 7.7140 - val_acc: 0.0000e+00\n",
      "Epoch 162/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.2367 - acc: 0.1436 - val_loss: 5.0111 - val_acc: 0.0300\n",
      "Epoch 163/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1667 - acc: 0.1564 - val_loss: 33.9852 - val_acc: 0.0000e+00\n",
      "Epoch 164/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.2347 - acc: 0.1529 - val_loss: 2.9414 - val_acc: 0.1650\n",
      "Epoch 165/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.2382 - acc: 0.1443 - val_loss: 2.3822 - val_acc: 0.1150\n",
      "Epoch 166/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1956 - acc: 0.1593 - val_loss: 9.4677 - val_acc: 0.0000e+00\n",
      "Epoch 167/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2156 - acc: 0.1414 - val_loss: 12.5621 - val_acc: 0.0000e+00\n",
      "Epoch 168/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.1740 - acc: 0.1607 - val_loss: 8.4813 - val_acc: 0.0000e+00\n",
      "Epoch 169/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.1580 - acc: 0.1471 - val_loss: 2.7428 - val_acc: 0.1350\n",
      "Epoch 170/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.1224 - acc: 0.1550 - val_loss: 4.0592 - val_acc: 0.0600\n",
      "Epoch 171/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.1727 - acc: 0.1429 - val_loss: 8.0264 - val_acc: 0.0050\n",
      "Epoch 172/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.2997 - acc: 0.1250 - val_loss: 10.7530 - val_acc: 0.0100\n",
      "Epoch 173/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.2418 - acc: 0.1436 - val_loss: 11.9667 - val_acc: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.1497 - acc: 0.1593 - val_loss: 12.5920 - val_acc: 0.0000e+00\n",
      "Epoch 175/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.1588 - acc: 0.1471 - val_loss: 13.9795 - val_acc: 0.0000e+00\n",
      "Epoch 176/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2153 - acc: 0.1479 - val_loss: 4.8842 - val_acc: 0.0350\n",
      "Epoch 177/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1284 - acc: 0.1421 - val_loss: 10.0574 - val_acc: 0.0050\n",
      "Epoch 178/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1468 - acc: 0.1471 - val_loss: 5.2299 - val_acc: 0.0250\n",
      "Epoch 179/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1857 - acc: 0.1514 - val_loss: 19.4845 - val_acc: 0.0000e+00\n",
      "Epoch 180/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.0844 - acc: 0.1607 - val_loss: 8.2381 - val_acc: 0.0000e+00\n",
      "Epoch 181/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.2283 - acc: 0.1393 - val_loss: 4.2348 - val_acc: 0.0500\n",
      "Epoch 182/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.0998 - acc: 0.1586 - val_loss: 7.6944 - val_acc: 0.0050\n",
      "Epoch 183/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.2274 - acc: 0.1364 - val_loss: 11.1807 - val_acc: 0.0000e+00\n",
      "Epoch 184/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1664 - acc: 0.1650 - val_loss: 2.2103 - val_acc: 0.1450\n",
      "Epoch 185/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1817 - acc: 0.1357 - val_loss: 9.9837 - val_acc: 0.0000e+00\n",
      "Epoch 186/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.0561 - acc: 0.1586 - val_loss: 7.7470 - val_acc: 0.0200\n",
      "Epoch 187/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1225 - acc: 0.1436 - val_loss: 13.1263 - val_acc: 0.0000e+00\n",
      "Epoch 188/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1306 - acc: 0.1643 - val_loss: 4.3221 - val_acc: 0.0350\n",
      "Epoch 189/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.0627 - acc: 0.1529 - val_loss: 15.5983 - val_acc: 0.0000e+00\n",
      "Epoch 190/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.0493 - acc: 0.1643 - val_loss: 4.1138 - val_acc: 0.0450\n",
      "Epoch 191/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1305 - acc: 0.1450 - val_loss: 8.1759 - val_acc: 0.0050\n",
      "Epoch 192/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.2174 - acc: 0.1600 - val_loss: 14.1173 - val_acc: 0.0000e+00\n",
      "Epoch 193/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.1565 - acc: 0.1557 - val_loss: 10.7161 - val_acc: 0.0200\n",
      "Epoch 194/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.0840 - acc: 0.1343 - val_loss: 2.8214 - val_acc: 0.1300\n",
      "Epoch 195/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1066 - acc: 0.1643 - val_loss: 6.8458 - val_acc: 0.0000e+00\n",
      "Epoch 196/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.2091 - acc: 0.1479 - val_loss: 7.6703 - val_acc: 0.0050\n",
      "Epoch 197/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1013 - acc: 0.1521 - val_loss: 3.6430 - val_acc: 0.1300\n",
      "Epoch 198/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1176 - acc: 0.1600 - val_loss: 12.2161 - val_acc: 0.0000e+00\n",
      "Epoch 199/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1378 - acc: 0.1529 - val_loss: 20.0784 - val_acc: 0.0000e+00\n",
      "Epoch 200/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1334 - acc: 0.1621 - val_loss: 2.3709 - val_acc: 0.1700\n",
      "Epoch 201/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.0430 - acc: 0.1671 - val_loss: 4.3332 - val_acc: 0.0350\n",
      "Epoch 202/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.0275 - acc: 0.1536 - val_loss: 10.7532 - val_acc: 0.0000e+00\n",
      "Epoch 203/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.2510 - acc: 0.1393 - val_loss: 8.6023 - val_acc: 0.0000e+00\n",
      "Epoch 204/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.0840 - acc: 0.1464 - val_loss: 7.6607 - val_acc: 0.0100\n",
      "Epoch 205/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1800 - acc: 0.1679 - val_loss: 7.2280 - val_acc: 0.0050\n",
      "Epoch 206/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1734 - acc: 0.1557 - val_loss: 13.4486 - val_acc: 0.0000e+00\n",
      "Epoch 207/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.0272 - acc: 0.1629 - val_loss: 13.2547 - val_acc: 0.0000e+00\n",
      "Epoch 208/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.2466 - acc: 0.1421 - val_loss: 3.9342 - val_acc: 0.0800\n",
      "Epoch 209/250\n",
      "1400/1400 [==============================] - 48s 35ms/step - loss: 2.1536 - acc: 0.1550 - val_loss: 6.7448 - val_acc: 0.0400\n",
      "Epoch 210/250\n",
      "1400/1400 [==============================] - 49s 35ms/step - loss: 2.0669 - acc: 0.1557 - val_loss: 2.5595 - val_acc: 0.1200\n",
      "Epoch 211/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.0713 - acc: 0.1493 - val_loss: 11.3542 - val_acc: 0.0050\n",
      "Epoch 212/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1055 - acc: 0.1657 - val_loss: 32.9624 - val_acc: 0.0000e+00\n",
      "Epoch 213/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 2.1358 - acc: 0.1593 - val_loss: 4.9005 - val_acc: 0.0350\n",
      "Epoch 214/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 2.1374 - acc: 0.1514 - val_loss: 5.8002 - val_acc: 0.0450\n",
      "Epoch 215/250\n",
      "1400/1400 [==============================] - 47s 34ms/step - loss: 2.1385 - acc: 0.1607 - val_loss: 5.6048 - val_acc: 0.0250\n",
      "Epoch 216/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.0486 - acc: 0.1743 - val_loss: 9.8864 - val_acc: 0.0100\n",
      "Epoch 217/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.1315 - acc: 0.1493 - val_loss: 5.0154 - val_acc: 0.0400\n",
      "Epoch 218/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 1.9908 - acc: 0.1614 - val_loss: 17.5510 - val_acc: 0.0000e+00\n",
      "Epoch 219/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.0528 - acc: 0.1507 - val_loss: 2.3503 - val_acc: 0.1800\n",
      "Epoch 220/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 2.0901 - acc: 0.1757 - val_loss: 11.6390 - val_acc: 0.0000e+00\n",
      "Epoch 221/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.1027 - acc: 0.1679 - val_loss: 5.8548 - val_acc: 0.0350\n",
      "Epoch 222/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.2029 - acc: 0.1464 - val_loss: 2.6104 - val_acc: 0.1500\n",
      "Epoch 223/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.2073 - acc: 0.1557 - val_loss: 8.1233 - val_acc: 0.0050\n",
      "Epoch 224/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0477 - acc: 0.1686 - val_loss: 2.5961 - val_acc: 0.1200\n",
      "Epoch 225/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0289 - acc: 0.1629 - val_loss: 6.5541 - val_acc: 0.0050\n",
      "Epoch 226/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0326 - acc: 0.1529 - val_loss: 7.4406 - val_acc: 0.0000e+00\n",
      "Epoch 227/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 1.9881 - acc: 0.1786 - val_loss: 8.4605 - val_acc: 0.0250\n",
      "Epoch 228/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0377 - acc: 0.1486 - val_loss: 6.0387 - val_acc: 0.0350\n",
      "Epoch 229/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0323 - acc: 0.1543 - val_loss: 4.8834 - val_acc: 0.0450\n",
      "Epoch 230/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0003 - acc: 0.1629 - val_loss: 5.4959 - val_acc: 0.0400\n",
      "Epoch 231/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0486 - acc: 0.1550 - val_loss: 5.9123 - val_acc: 0.0150\n",
      "Epoch 232/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 46s 33ms/step - loss: 1.9881 - acc: 0.1650 - val_loss: 2.7623 - val_acc: 0.1350\n",
      "Epoch 233/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0383 - acc: 0.1621 - val_loss: 15.0509 - val_acc: 0.0100\n",
      "Epoch 234/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 1.8977 - acc: 0.1657 - val_loss: 4.3025 - val_acc: 0.0300\n",
      "Epoch 235/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 2.0368 - acc: 0.1564 - val_loss: 16.9197 - val_acc: 0.0000e+00\n",
      "Epoch 236/250\n",
      "1400/1400 [==============================] - 48s 34ms/step - loss: 2.0531 - acc: 0.1557 - val_loss: 2.3984 - val_acc: 0.1200\n",
      "Epoch 237/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 1.9905 - acc: 0.1486 - val_loss: 3.5891 - val_acc: 0.0500\n",
      "Epoch 238/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 1.9617 - acc: 0.1693 - val_loss: 11.0840 - val_acc: 0.0000e+00\n",
      "Epoch 239/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0134 - acc: 0.1593 - val_loss: 3.7028 - val_acc: 0.0600\n",
      "Epoch 240/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0324 - acc: 0.1543 - val_loss: 8.7057 - val_acc: 0.0000e+00\n",
      "Epoch 241/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0971 - acc: 0.1536 - val_loss: 2.2740 - val_acc: 0.1800\n",
      "Epoch 242/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0531 - acc: 0.1571 - val_loss: 9.3256 - val_acc: 0.0100\n",
      "Epoch 243/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.1316 - acc: 0.1479 - val_loss: 7.2503 - val_acc: 0.0150\n",
      "Epoch 244/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 1.8508 - acc: 0.1550 - val_loss: 7.0622 - val_acc: 0.0100\n",
      "Epoch 245/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0219 - acc: 0.1421 - val_loss: 15.9362 - val_acc: 0.0000e+00\n",
      "Epoch 246/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0208 - acc: 0.1607 - val_loss: 8.7494 - val_acc: 0.0000e+00\n",
      "Epoch 247/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 2.0273 - acc: 0.1543 - val_loss: 2.1437 - val_acc: 0.1350\n",
      "Epoch 248/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 1.9937 - acc: 0.1657 - val_loss: 2.2682 - val_acc: 0.1600\n",
      "Epoch 249/250\n",
      "1400/1400 [==============================] - 47s 33ms/step - loss: 1.9774 - acc: 0.1614 - val_loss: 4.5971 - val_acc: 0.0400\n",
      "Epoch 250/250\n",
      "1400/1400 [==============================] - 46s 33ms/step - loss: 1.9046 - acc: 0.1664 - val_loss: 3.6527 - val_acc: 0.0800\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train, Y_train, batch_size=10, epochs=250, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('Ultimo_Intento.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 480, 640, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375]\n",
      "[25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400]\n"
     ]
    }
   ],
   "source": [
    "X_test[25:50].shape\n",
    "a = list(range(0, 400,25))\n",
    "b = list(range(25, 425,25))\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "32\n",
      "39\n",
      "39\n",
      "36\n",
      "34\n",
      "27\n",
      "34\n",
      "26\n",
      "24\n",
      "18\n",
      "20\n",
      "22\n",
      "21\n",
      "15\n",
      "16\n",
      "16\n",
      "20\n",
      "28\n",
      "22\n",
      "20\n",
      "25\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "23\n",
      "21\n",
      "25\n",
      "25\n",
      "22\n",
      "21\n",
      "21\n",
      "20\n",
      "17\n",
      "21\n",
      "29\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "21\n",
      "19\n",
      "18\n",
      "24\n",
      "22\n",
      "21\n",
      "21\n",
      "27\n",
      "27\n",
      "17\n",
      "12\n",
      "17\n",
      "20\n",
      "21\n",
      "25\n",
      "26\n",
      "28\n",
      "28\n",
      "20\n",
      "18\n",
      "18\n",
      "20\n",
      "22\n",
      "22\n",
      "22\n",
      "31\n",
      "31\n",
      "30\n",
      "30\n",
      "31\n",
      "32\n",
      "36\n",
      "32\n",
      "50\n",
      "42\n",
      "41\n",
      "30\n",
      "28\n",
      "29\n",
      "33\n",
      "34\n",
      "39\n",
      "35\n",
      "27\n",
      "29\n",
      "27\n",
      "29\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "24\n",
      "25\n",
      "29\n",
      "26\n",
      "28\n",
      "26\n",
      "28\n",
      "27\n",
      "27\n",
      "26\n",
      "21\n",
      "21\n",
      "22\n",
      "23\n",
      "21\n",
      "29\n",
      "24\n",
      "21\n",
      "21\n",
      "23\n",
      "38\n",
      "47\n",
      "28\n",
      "28\n",
      "31\n",
      "32\n",
      "31\n",
      "34\n",
      "32\n",
      "29\n",
      "40\n",
      "27\n",
      "31\n",
      "29\n",
      "29\n",
      "30\n",
      "30\n",
      "32\n",
      "35\n",
      "35\n",
      "40\n",
      "38\n",
      "30\n",
      "33\n",
      "33\n",
      "40\n",
      "41\n",
      "40\n",
      "29\n",
      "26\n",
      "25\n",
      "25\n",
      "32\n",
      "33\n",
      "24\n",
      "27\n",
      "33\n",
      "29\n",
      "28\n",
      "27\n",
      "28\n",
      "26\n",
      "28\n",
      "27\n",
      "29\n",
      "30\n",
      "27\n",
      "29\n",
      "27\n",
      "32\n",
      "29\n",
      "28\n",
      "30\n",
      "34\n",
      "37\n",
      "34\n",
      "36\n",
      "31\n",
      "26\n",
      "28\n",
      "26\n",
      "28\n",
      "33\n",
      "30\n",
      "33\n",
      "34\n",
      "42\n",
      "37\n",
      "46\n",
      "38\n",
      "29\n",
      "29\n",
      "35\n",
      "34\n",
      "33\n",
      "31\n",
      "30\n",
      "24\n",
      "26\n",
      "26\n",
      "27\n",
      "28\n",
      "28\n",
      "33\n",
      "28\n",
      "25\n",
      "22\n",
      "23\n",
      "29\n",
      "28\n",
      "26\n",
      "27\n",
      "24\n",
      "30\n",
      "22\n",
      "21\n",
      "20\n",
      "25\n",
      "27\n",
      "27\n",
      "25\n",
      "27\n",
      "25\n",
      "25\n",
      "27\n",
      "26\n",
      "29\n",
      "31\n",
      "36\n",
      "33\n",
      "30\n",
      "35\n",
      "31\n",
      "26\n",
      "23\n",
      "28\n",
      "26\n",
      "26\n",
      "24\n",
      "22\n",
      "27\n",
      "30\n",
      "29\n",
      "33\n",
      "34\n",
      "28\n",
      "23\n",
      "21\n",
      "24\n",
      "22\n",
      "23\n",
      "32\n",
      "31\n",
      "37\n",
      "31\n",
      "31\n",
      "31\n",
      "32\n",
      "29\n",
      "31\n",
      "31\n",
      "30\n",
      "31\n",
      "30\n",
      "26\n",
      "32\n",
      "33\n",
      "21\n",
      "20\n",
      "19\n",
      "22\n",
      "21\n",
      "27\n",
      "28\n",
      "27\n",
      "20\n",
      "20\n",
      "29\n",
      "28\n",
      "32\n",
      "34\n",
      "32\n",
      "32\n",
      "29\n",
      "36\n",
      "31\n",
      "30\n",
      "35\n",
      "35\n",
      "36\n",
      "35\n",
      "33\n",
      "29\n",
      "31\n",
      "27\n",
      "30\n",
      "29\n",
      "28\n",
      "41\n",
      "41\n",
      "36\n",
      "27\n",
      "26\n",
      "25\n",
      "28\n",
      "33\n",
      "34\n",
      "39\n",
      "39\n",
      "42\n",
      "32\n",
      "24\n",
      "26\n",
      "27\n",
      "29\n",
      "28\n",
      "28\n",
      "30\n",
      "28\n",
      "30\n",
      "27\n",
      "26\n",
      "36\n",
      "37\n",
      "39\n",
      "45\n",
      "36\n",
      "34\n",
      "43\n",
      "35\n",
      "27\n",
      "30\n",
      "25\n",
      "26\n",
      "26\n",
      "28\n",
      "29\n",
      "19\n",
      "20\n",
      "23\n",
      "26\n",
      "31\n",
      "29\n",
      "26\n",
      "27\n",
      "25\n",
      "25\n",
      "28\n",
      "28\n",
      "25\n",
      "28\n",
      "32\n",
      "33\n",
      "36\n",
      "28\n",
      "28\n",
      "30\n",
      "34\n",
      "27\n",
      "31\n",
      "29\n",
      "28\n",
      "29\n",
      "29\n",
      "40\n",
      "33\n",
      "34\n",
      "27\n",
      "27\n",
      "26\n",
      "31\n",
      "34\n",
      "35\n",
      "32\n",
      "32\n",
      "28\n",
      "36\n",
      "32\n",
      "29\n",
      "29\n",
      "28\n",
      "28\n",
      "27\n",
      "25\n",
      "23\n",
      "24\n",
      "28\n",
      "26\n",
      "32\n",
      "31\n",
      "29\n",
      "28\n",
      "26\n",
      "26\n",
      "26\n",
      "31\n",
      "32\n",
      "31\n",
      "34\n",
      "26\n",
      "27\n",
      "23\n",
      "26\n",
      "27\n",
      "24\n",
      "26\n",
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(a,b):\n",
    "    prediction = model1.predict(X_test[i:j])\n",
    "    for w in prediction:\n",
    "        print(int(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
